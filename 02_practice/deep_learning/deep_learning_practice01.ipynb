{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83e7c480",
   "metadata": {},
   "source": [
    "`homework_torch_tensor_251215.ipynb`ì— ì‘ì„±í•˜ì„¸ìš”. # 30\n",
    "\n",
    "### ğŸ’¡ ì¡°ê±´\n",
    "\n",
    "* ì…ë ¥: ìƒ˜í”Œ ìˆ˜ 6ê°œ, íŠ¹ì„± ìˆ˜ 10ê°œ\n",
    "* ì€ë‹‰ì¸µ: ì…ë ¥ 10 â†’ ì¶œë ¥ 8 (í™œì„±í™” í•¨ìˆ˜: `tanh`)\n",
    "* ì¶œë ¥ì¸µ: ì…ë ¥ 8 â†’ ì¶œë ¥ 4 (í™œì„±í™” í•¨ìˆ˜: `softmax`)\n",
    "* PyTorch ì‚¬ìš©\n",
    "\n",
    "\n",
    "\n",
    "### ë¬¸ì œ 1. ì§ì ‘ ê°€ì¤‘ì¹˜/ì ˆí¸ì„ ì„ ì–¸í•˜ê³  ìˆœì „íŒŒ ê³„ì‚°\n",
    "\n",
    "ë‹¤ìŒ ì¡°ê±´ì— ë§ê²Œ PyTorch í…ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ forward ê³„ì‚°ì„ ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„í•˜ì„¸ìš”.\n",
    "\n",
    "**ğŸ“Œ ìš”êµ¬ì‚¬í•­**\n",
    "\n",
    "1. ì…ë ¥ `X`ëŠ” `torch.randn(6, 10)` ìœ¼ë¡œ ìƒì„±í•œë‹¤.\n",
    "2. `W1`, `b1`, `W2`, `b2`ë„ torchì˜ `randn`ì„ ì´ìš©í•´ ì§ì ‘ ì •ì˜í•œë‹¤.\n",
    "3. ì€ë‹‰ì¸µì—ì„œëŠ” `tanh`, ì¶œë ¥ì¸µì—ì„œëŠ” `softmax`ë¥¼ ì‚¬ìš©í•œë‹¤.\n",
    "4. ìµœì¢… ê²°ê³¼ëŠ” `(6, 4)` í¬ê¸°ì˜ í™•ë¥  ë²¡í„°ì´ì–´ì•¼ í•œë‹¤.\n",
    "\n",
    "### ë¬¸ì œ 2. ìœ„ ë„¤íŠ¸ì›Œí¬ë¥¼ PyTorch ëª¨ë¸ í´ë˜ìŠ¤ë¡œ ì‘ì„±\n",
    "\n",
    "ë‹¤ìŒ ì¡°ê±´ì— ë§ëŠ” `nn.Module` í´ë˜ìŠ¤ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "\n",
    "1. `__init__`ì— `nn.Linear(10, 8)`ê³¼ `nn.Linear(8, 4)`ë¥¼ ì •ì˜í•œë‹¤.\n",
    "2. `forward`ì—ì„œëŠ” `tanh` â†’ `softmax` ìˆœìœ¼ë¡œ í™œì„±í™” í•¨ìˆ˜ë¥¼ ì ìš©í•œë‹¤.\n",
    "3. ì„ì˜ì˜ ì…ë ¥ `X = torch.randn(6, 10)`ì„ ëª¨ë¸ì— ë„£ì–´ ì¶œë ¥ ê²°ê³¼ë¥¼ í™•ì¸í•œë‹¤.\n",
    "\n",
    "\n",
    "\n",
    "### âœ¨ ë¬¸ì œ3. ì¸µë³„ ê°€ì¤‘ì¹˜/í¸í–¥ ì¶œë ¥\n",
    "\n",
    "ëª¨ë¸ ë‚´ ê°€ì¤‘ì¹˜ì™€ í¸í–¥ ê°’ì„ í™•ì¸í•˜ê³  ì¶œë ¥í•˜ì„¸ìš”.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2019492d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d54ec41",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì¡°ê±´\n",
    "\n",
    "* ì…ë ¥: ìƒ˜í”Œ ìˆ˜ 6ê°œ, íŠ¹ì„± ìˆ˜ 10ê°œ\n",
    "* ì€ë‹‰ì¸µ: ì…ë ¥ 10 â†’ ì¶œë ¥ 8 (í™œì„±í™” í•¨ìˆ˜: `tanh`)\n",
    "* ì¶œë ¥ì¸µ: ì…ë ¥ 8 â†’ ì¶œë ¥ 4 (í™œì„±í™” í•¨ìˆ˜: `softmax`)\n",
    "* PyTorch ì‚¬ìš©\n",
    "\n",
    "\n",
    "\n",
    "### ë¬¸ì œ 1. ì§ì ‘ ê°€ì¤‘ì¹˜/ì ˆí¸ì„ ì„ ì–¸í•˜ê³  ìˆœì „íŒŒ ê³„ì‚°\n",
    "\n",
    "ë‹¤ìŒ ì¡°ê±´ì— ë§ê²Œ PyTorch í…ì„œë¥¼ ì‚¬ìš©í•˜ì—¬ forward ê³„ì‚°ì„ ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„í•˜ì„¸ìš”.\n",
    "\n",
    "**ğŸ“Œ ìš”êµ¬ì‚¬í•­**\n",
    "\n",
    "1. ì…ë ¥ `X`ëŠ” `torch.randn(6, 10)` ìœ¼ë¡œ ìƒì„±í•œë‹¤.\n",
    "2. `W1`, `b1`, `W2`, `b2`ë„ torchì˜ `randn`ì„ ì´ìš©í•´ ì§ì ‘ ì •ì˜í•œë‹¤.\n",
    "3. ì€ë‹‰ì¸µì—ì„œëŠ” `tanh`, ì¶œë ¥ì¸µì—ì„œëŠ” `softmax`ë¥¼ ì‚¬ìš©í•œë‹¤.\n",
    "4. ìµœì¢… ê²°ê³¼ëŠ” `(6, 4)` í¬ê¸°ì˜ í™•ë¥  ë²¡í„°ì´ì–´ì•¼ í•œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9f39fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# 1ï¸âƒ£ ì…ë ¥ ë°ì´í„°\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1ï¸âƒ£ ì…ë ¥ ë°ì´í„°\n",
    "X = torch.randn(6, 10)   # (ìƒ˜í”Œ 6, íŠ¹ì„± 10)\n",
    "\n",
    "# 2ï¸âƒ£ ê°€ì¤‘ì¹˜ì™€ í¸í–¥ ì§ì ‘ ì„ ì–¸\n",
    "W1 = torch.randn(10, 8)\n",
    "b1 = torch.randn(8)\n",
    "\n",
    "W2 = torch.randn(8, 4)\n",
    "b2 = torch.randn(4)\n",
    "\n",
    "# 3ï¸âƒ£ ìˆœì „íŒŒ ê³„ì‚°\n",
    "z1 = X @ W1 + b1         # (6, 8)\n",
    "a1 = torch.tanh(z1)     # tanh í™œì„±í™”\n",
    "\n",
    "z2 = a1 @ W2 + b2       # (6, 4)\n",
    "output = F.softmax(z2, dim=1)  # softmax\n",
    "\n",
    "# 4ï¸âƒ£ ê²°ê³¼ í™•ì¸\n",
    "print(output.shape)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994e2226",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì¡°ê±´\n",
    "\n",
    "* ì…ë ¥: ìƒ˜í”Œ ìˆ˜ 6ê°œ, íŠ¹ì„± ìˆ˜ 10ê°œ\n",
    "* ì€ë‹‰ì¸µ: ì…ë ¥ 10 â†’ ì¶œë ¥ 8 (í™œì„±í™” í•¨ìˆ˜: `tanh`)\n",
    "* ì¶œë ¥ì¸µ: ì…ë ¥ 8 â†’ ì¶œë ¥ 4 (í™œì„±í™” í•¨ìˆ˜: `softmax`)\n",
    "* PyTorch ì‚¬ìš©\n",
    "\n",
    "### ë¬¸ì œ 2. ìœ„ ë„¤íŠ¸ì›Œí¬ë¥¼ PyTorch ëª¨ë¸ í´ë˜ìŠ¤ë¡œ ì‘ì„±\n",
    "\n",
    "ë‹¤ìŒ ì¡°ê±´ì— ë§ëŠ” `nn.Module` í´ë˜ìŠ¤ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n",
    "\n",
    "ğŸ“Œ ìš”êµ¬ì‚¬í•­\n",
    "\n",
    "1. `__init__`ì— `nn.Linear(10, 8)`ê³¼ `nn.Linear(8, 4)`ë¥¼ ì •ì˜í•œë‹¤.\n",
    "2. `forward`ì—ì„œëŠ” `tanh` â†’ `softmax` ìˆœìœ¼ë¡œ í™œì„±í™” í•¨ìˆ˜ë¥¼ ì ìš©í•œë‹¤.\n",
    "3. ì„ì˜ì˜ ì…ë ¥ `X = torch.randn(6, 10)`ì„ ëª¨ë¸ì— ë„£ì–´ ì¶œë ¥ ê²°ê³¼ë¥¼ í™•ì¸í•œë‹¤.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba7fe6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 8)\n",
    "        self.fc2 = nn.Linear(8, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = F.softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "\n",
    "# ëª¨ë¸ ìƒì„±\n",
    "model = SimpleNN()\n",
    "\n",
    "# ì…ë ¥ ë°ì´í„°\n",
    "X = torch.randn(6, 10)\n",
    "\n",
    "# ìˆœì „íŒŒ\n",
    "output = model(X)\n",
    "\n",
    "print(output.shape)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d61533a",
   "metadata": {},
   "source": [
    "### ğŸ’¡ ì¡°ê±´\n",
    "\n",
    "* ì…ë ¥: ìƒ˜í”Œ ìˆ˜ 6ê°œ, íŠ¹ì„± ìˆ˜ 10ê°œ\n",
    "* ì€ë‹‰ì¸µ: ì…ë ¥ 10 â†’ ì¶œë ¥ 8 (í™œì„±í™” í•¨ìˆ˜: `tanh`)\n",
    "* ì¶œë ¥ì¸µ: ì…ë ¥ 8 â†’ ì¶œë ¥ 4 (í™œì„±í™” í•¨ìˆ˜: `softmax`)\n",
    "* PyTorch ì‚¬ìš©\n",
    "\n",
    "### âœ¨ ë¬¸ì œ3. ì¸µë³„ ê°€ì¤‘ì¹˜/í¸í–¥ ì¶œë ¥\n",
    "\n",
    "ëª¨ë¸ ë‚´ ê°€ì¤‘ì¹˜ì™€ í¸í–¥ ê°’ì„ í™•ì¸í•˜ê³  ì¶œë ¥í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc4f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC1 Weight:\n",
      " Parameter containing:\n",
      "tensor([[ 0.2124, -0.2696,  0.1493, -0.1475, -0.0955,  0.2708,  0.0080,  0.2758,\n",
      "         -0.0815, -0.2742],\n",
      "        [ 0.1844, -0.1719,  0.2768, -0.2707, -0.0994,  0.1865,  0.0076,  0.1814,\n",
      "         -0.2283,  0.1551],\n",
      "        [ 0.0605, -0.3061, -0.3045,  0.1812,  0.1627, -0.0061, -0.2188,  0.2359,\n",
      "         -0.0554,  0.2354],\n",
      "        [-0.0238,  0.0291, -0.2034, -0.2960, -0.0584,  0.0365, -0.2860,  0.1757,\n",
      "         -0.0418, -0.0283],\n",
      "        [-0.2168,  0.0693,  0.2049,  0.1004, -0.2020, -0.0166,  0.1680,  0.1200,\n",
      "          0.2367,  0.2118],\n",
      "        [ 0.1313,  0.1395,  0.2421, -0.1768,  0.1013,  0.2103,  0.2636,  0.1602,\n",
      "          0.2579, -0.1543],\n",
      "        [-0.0050, -0.1721, -0.3009,  0.0434, -0.2627, -0.3160, -0.2252,  0.2483,\n",
      "         -0.2867, -0.2656],\n",
      "        [ 0.1125,  0.0746,  0.1732,  0.0994,  0.1108,  0.0593,  0.1032, -0.2380,\n",
      "          0.2475,  0.2432]], requires_grad=True)\n",
      "FC1 Bias:\n",
      " Parameter containing:\n",
      "tensor([ 0.1338, -0.0821,  0.1192, -0.0016, -0.1689,  0.2695, -0.1620, -0.0973],\n",
      "       requires_grad=True)\n",
      "FC2 Weight:\n",
      " Parameter containing:\n",
      "tensor([[-0.3496, -0.1799,  0.3336,  0.1627, -0.2697,  0.0907,  0.2309, -0.1933],\n",
      "        [ 0.2094,  0.0338, -0.0240, -0.3511, -0.1685,  0.2557,  0.3389, -0.2308],\n",
      "        [ 0.0866, -0.3005,  0.1196,  0.3030, -0.0075,  0.2850,  0.1083,  0.3163],\n",
      "        [-0.1062,  0.2608,  0.3003, -0.0387,  0.0547,  0.1189,  0.1734, -0.2773]],\n",
      "       requires_grad=True)\n",
      "FC2 Bias:\n",
      " Parameter containing:\n",
      "tensor([ 0.0011, -0.1768,  0.0738, -0.1715], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# ì²« ë²ˆì§¸ ì¸µ\n",
    "print(\"FC1 Weight:\\n\", model.fc1.weight)\n",
    "print(\"FC1 Bias:\\n\", model.fc1.bias)\n",
    "\n",
    "# ë‘ ë²ˆì§¸ ì¸µ\n",
    "print(\"FC2 Weight:\\n\", model.fc2.weight)\n",
    "print(\"FC2 Bias:\\n\", model.fc2.bias)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pystudy_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
